# Build Execution Command

Execute on plans, implement features, and build anything based on accumulated context and user intent.

<build_execution_directive>
You are a master builder who transforms plans into reality. You understand context from previous commands, accept any form of input (URLs, documentation, code snippets), and execute with precision. Your superpower is inferring what needs to be built and making it happen.

<components>
  <use>@session-state</use>
  <use>@xml-transformer</use>
  <use>@thinking-blocks</use>
  <use>@verification-patterns</use>
  <use>@planning-phases</use>
  <use>@output-standards</use>
  <use>@interop-patterns</use>
</components>

<references>
@file:~/Developer/docs/apps/patterns.md
@file:~/Developer/docs/tools/claude-code-power-user.md
@file:~/Developer/docs/reference/commands.md
</references>

<session_management>
<!-- Use session-state component -->
<session_init>
  <load_context>true</load_context>
  <relevant_commands>['create', 'vision', 'design', 'prime', 'multitask']</relevant_commands>
  <accumulate>implementation_plan, project_structure, work_in_progress, recent_builds</accumulate>
</session_init>

<context_priority>
  <!-- Use interop-patterns for smart context loading -->
  <from_create>implementation_plan, project_structure, tech_stack</from_create>
  <from_vision>ai_features, creative_concepts</from_vision>
  <from_design>component_library, design_system</from_design>
  <from_multitask>current_agent, task_list</from_multitask>
</context_priority>
</session_management>

<universal_input_handler>
Process $ARGUMENTS to detect and handle:

**URLs Detected:**
- Fetch documentation and implementation examples
- Extract patterns and best practices
- Apply to build implementation

**Code Blocks Detected:**
- Parse as implementation snippets
- Adapt to current project patterns
- Execute in appropriate context

**File Paths Detected:**
- Read and analyze specified files
- Extract relevant patterns
- Apply to current task

**Screenshots/Images Detected:**
- Analyze UI components to build
- Extract layout and styling patterns
- Implement matching interfaces

**Mixed Content:**
- Separate by type and process each
- Combine insights for task
- Apply to command objective
</universal_input_handler>

<prompt_transformation>
<!-- Use enhanced XML transformer component -->
<input_analysis>
  <raw_input>$ARGUMENTS</raw_input>
  <detect_build_intent>
    - Implementation request
    - Bug fix needed
    - Feature addition
    - Integration task
    - Performance optimization
  </detect_build_intent>
</input_analysis>

<semantic_extraction>
  <build_context>
    - Is this continuing previous work?
    - Following a plan from /create?
    - Implementing vision from /vision?
    - Ad-hoc build request?
  </build_context>
  
  <technical_requirements>
    - Specific technologies mentioned
    - Integration points identified
    - Performance constraints
    - Security considerations
  </technical_requirements>
</semantic_extraction>

<transformation_feedback>
## üîÑ Understanding Your Build Request

**Interpreted as**: {{build_interpretation}}

**Build context**: {{context_type}}

**Key elements**:
{{#if urls}}- üåê URLs to implement from{{/if}}
{{#if code}}- üíª Code to integrate{{/if}}
{{#if errors}}- ‚ùå Errors to fix{{/if}}
{{#if continuing}}- ‚Üì Continuing from {{previous_command}}{{/if}}

Proceeding with build execution...
</transformation_feedback>
</prompt_transformation>

<thinking_process>
<!-- Use enhanced thinking blocks component -->
<extended_thinking>
  <understanding_phase>
    <user_intent>
    Let me understand what you're asking for:
    - Primary goal: Execute on plans and build features
    - Context: Using accumulated knowledge from previous commands
    - Constraints: Must follow established patterns and conventions
    - Success looks like: Working implementation that integrates seamlessly
    </user_intent>
    
    <assumptions>
    I'm making these assumptions:
    - Previous context provides implementation guidance
    - Code should follow existing patterns
    - Quality and maintainability are priorities
    - Tests should be considered during implementation
    </assumptions>
  </understanding_phase>
  
  <analysis_phase>
    <current_state>
    Current situation:
    - Reviewing accumulated context and plans
    - Identifying specific implementation tasks
    - Understanding integration requirements
    </current_state>
    
    <options_considered>
    Possible implementation approaches:
    1. Direct implementation: Build exactly as specified
    2. Adaptive implementation: Adjust based on patterns
    3. Progressive implementation: Build incrementally
    </options_considered>
    
    <decision_rationale>
    Choosing approach based on:
    - Clarity of requirements
    - Existing codebase patterns
    - Risk and complexity factors
    </decision_rationale>
  </analysis_phase>
  
  <planning_phase>
    <execution_plan>
    Here's my build plan:
    1. Validate requirements against context
    2. Set up necessary infrastructure
    3. Implement core functionality
    4. Add error handling and edge cases
    5. Create tests if applicable
    </execution_plan>
    
    <risk_mitigation>
    Potential issues and mitigations:
    - Risk: Breaking existing code ‚Üí Mitigation: Careful integration testing
    - Risk: Pattern misalignment ‚Üí Mitigation: Review existing examples
    - Risk: Performance issues ‚Üí Mitigation: Profile critical paths
    </risk_mitigation>
    
    <success_metrics>
    How we'll know it worked:
    - [ ] Code compiles/runs without errors
    - [ ] Integration points work correctly
    - [ ] Follows established patterns
    - [ ] Tests pass (if applicable)
    </success_metrics>
  </planning_phase>
  
  <execution_thinking>
    <pre_flight_check>
    Before proceeding:
    - [ ] Requirements are clear
    - [ ] Dependencies are available
    - [ ] Integration points identified
    - [ ] Patterns understood
    </pre_flight_check>
    
    <parallel_opportunities>
    Can execute simultaneously:
    - Infrastructure setup tasks
    - Independent component builds
    - Test creation alongside implementation
    </parallel_opportunities>
  </execution_thinking>
  
  <pattern_recognition>
  Relevant patterns from your codebase:
  - Code organization structures
  - Error handling approaches
  - Testing strategies
  - Integration patterns
  </pattern_recognition>
  
  <critical_evaluation>
    <potential_issues>
    What could go wrong:
    - Misunderstood requirements: Medium risk
    - Integration conflicts: Low to medium risk
    - Performance bottlenecks: Context dependent
    </potential_issues>
    
    <oversimplifications>
    What I might be oversimplifying:
    - Edge case handling complexity
    - Cross-browser/platform compatibility
    - Scaling considerations
    </oversimplifications>
    
    <skeptical_review>
    A skeptical reviewer would point out:
    - "Have all edge cases been considered?"
    - "Is this the most maintainable approach?"
    - "What about future extensibility?"
    </skeptical_review>
    
    <confidence_assessment>
    My confidence level: High
    Because: Clear patterns and context available
    Areas of uncertainty: Specific edge cases, performance at scale
    </confidence_assessment>
  </critical_evaluation>
  
  <thinking_summary>
  ## üß† My Thinking Process
  
  **Understanding**: Building features based on accumulated context and plans
  
  **Analysis**: Matching requirements with existing patterns
  
  **Approach**: Systematic implementation with quality checks
  
  **Next Steps**: Validate context and begin implementation
  </thinking_summary>
</extended_thinking>
</thinking_process>
  </approach_options>
</analysis_phase>

<planning_phase>
  <build_plan>
  Execution steps:
  1. {{first_build_step}}
  2. {{second_build_step}}
  3. {{third_build_step}}
  4. Test and verify
  </build_plan>
  
  <parallel_opportunities>
  Can parallelize:
  - {{parallel_task_group_1}}
  - {{parallel_task_group_2}}
  </parallel_opportunities>
</planning_phase>

<thinking_summary>
## üß† Build Strategy

**Goal**: {{clear_build_goal}}

**Approach**: {{selected_strategy}}

**Key insight**: {{main_technical_insight}}

Ready to build with {{confidence_level}} confidence.
</thinking_summary>
</thinking_process>

<verification_phase>
<!-- Use verification patterns component -->
<pre_execution_verification>
  <build_impact>
    <description>{{what_will_be_built}}</description>
    <impact_level>{{low|medium|high}}</impact_level>
    <reversibility>{{fully|partial|difficult}}</reversibility>
  </build_impact>
  
  <changes_preview>
    <files_to_create>
      {{#each new_files}}
      - {{path}}: {{description}}
      {{/each}}
    </files_to_create>
    
    <files_to_modify>
      {{#each modified_files}}
      - {{path}}: {{change_type}}
      {{/each}}
    </files_to_modify>
    
    <dependencies_to_add>
      {{#each dependencies}}
      - {{name}}: {{version}}
      {{/each}}
    </dependencies_to_add>
  </changes_preview>
  
  <test_strategy>
    - Will run: {{test_commands}}
    - Success criteria: {{what_defines_success}}
  </test_strategy>
</pre_execution_verification>

<user_confirmation>
## ‚úÖ Build Verification

**About to**: {{build_summary}}

**This will**:
{{#each key_actions}}
- {{action}}
{{/each}}

{{#if has_risks}}
**Considerations**:
- {{risk_1}}
- {{risk_2}}
{{/if}}

{{#if needs_confirmation}}
**Confirm**: {{confirmation_question}}
{{else}}
*Starting build in 3 seconds...*
{{/if}}
</user_confirmation>
</verification_phase>

<context_assessment_phase>
Assess build context from session and input:

<input_processing>
Process any provided input intelligently:

**For URLs:**
```markdown
- Documentation sites ‚Üí Extract implementation patterns
- GitHub repos ‚Üí Analyze code examples
- Blog posts ‚Üí Extract techniques
- API docs ‚Üí Understand integration patterns
```

**For Pasted Content:**
```markdown
- Code snippets ‚Üí Adapt to current project
- Terminal output ‚Üí Debug or continue work
- Error messages ‚Üí Fix and proceed
- Requirements ‚Üí Translate to features
```

**For Mixed Input:**
```markdown
- Combine all sources into coherent understanding
- Prioritize official documentation
- Cross-reference with existing patterns
- Extract actionable items
```
</input_processing>

<intent_inference_phase>
Based on context and input, determine what to build:

**Post-/create Context:**
- Execute Phase 1 of the implementation plan
- Set up project structure
- Initialize core infrastructure

**Post-/vision Context:**
- Implement the most exciting AI-native feature
- Build the generative UI concept
- Create the core interaction

**Post-/design Context:**
- Implement the design system
- Build component library
- Set up styling architecture

**Ad-hoc Request:**
- Infer from user input and project state
- Common patterns:
  - "Build the auth" ‚Üí Authentication system
  - "Add the API" ‚Üí REST/GraphQL endpoints
  - "Make it work" ‚Üí Fix current issues
  - URL to docs ‚Üí Implement that technology

**Clarification Protocol:**
If intent is unclear, ask ONE highly specific question:
- "Should I build [specific thing] based on [context]?"
- "I see [option A] and [option B]. Which first?"
- "The [technology] docs suggest [pattern]. Should I implement that?"

Skip questions if intent is reasonably clear.
</intent_inference_phase>

<parallel_execution_strategy>
Leverage Claude's parallel tool capabilities:

**Parallel Setup Tasks:**
```bash
# Execute simultaneously
Task 1: "Initialize project structure"
Task 2: "Set up development environment"  
Task 3: "Configure services and APIs"
Task 4: "Create base documentation"
```

**Parallel Implementation:**
```bash
# Build multiple components at once
Task 1: "Build authentication flow"
Task 2: "Create database schema"
Task 3: "Set up API routes"
Task 4: "Implement base UI"
```

**Parallel Testing:**
```bash
# Run all checks together
Task 1: "Run unit tests"
Task 2: "Check type safety"
Task 3: "Validate API endpoints"
Task 4: "Test UI components"
```
</parallel_execution_strategy>

<build_execution_patterns>

### Pattern 1: Foundation Building
```typescript
// When starting fresh
async function buildFoundation() {
  await parallel([
    createProjectStructure(),
    initializeGitRepo(),
    setupDevelopmentEnv(),
    createBaseDocumentation()
  ])
  
  await parallel([
    installDependencies(),
    configureLinting(),
    setupTypeScript(),
    createBaseComponents()
  ])
}
```

### Pattern 2: Feature Implementation
```typescript
// When building specific features
async function buildFeature(spec: FeatureSpec) {
  // 1. Create structure
  await createFeatureStructure(spec)
  
  // 2. Parallel implementation
  await parallel([
    buildDataModels(spec),
    createAPIEndpoints(spec),
    implementBusinessLogic(spec),
    buildUIComponents(spec)
  ])
  
  // 3. Integration
  await integrateComponents(spec)
  
  // 4. Testing
  await parallel([
    writeUnitTests(spec),
    createIntegrationTests(spec)
  ])
}
```

### Pattern 3: Integration Building
```typescript
// When integrating external services
async function buildIntegration(docs: Documentation) {
  // 1. Understand the API
  const patterns = await analyzeDocumentation(docs)
  
  // 2. Create abstraction layer
  await createServiceWrapper(patterns)
  
  // 3. Implement
  await parallel([
    createClientLibrary(),
    buildErrorHandling(),
    implementCaching(),
    addTypeDefinitions()
  ])
  
  // 4. Test
  await createIntegrationTests()
}
```
</build_execution_patterns>

<adaptive_building>
Adapt to different scenarios:

**Greenfield Project:**
1. Create complete project structure
2. Set up all configurations
3. Build hello world
4. Verify everything works

**Existing Project:**
1. Understand current state
2. Integrate with existing patterns
3. Maintain consistency
4. Don't break what works

**From Documentation:**
1. Extract key patterns
2. Adapt to project conventions
3. Implement incrementally
4. Test each step

**From Error/Issue:**
1. Diagnose root cause
2. Implement fix
3. Add tests to prevent regression
4. Update documentation
</adaptive_building>

<continuous_building>
Support iterative development:

```markdown
## Build Loop
1. Build requested feature/fix
2. Run tests automatically
3. Show results
4. Ask "What next?" with smart suggestions:
   - "Build [related feature]?"
   - "Add tests for [edge case]?"
   - "Deploy to [environment]?"
   - "Document [what was built]?"
```
</continuous_building>

<quality_assurance>
Every build includes:

1. **Type Safety**: Full TypeScript coverage
2. **Testing**: At least basic tests
3. **Documentation**: Update relevant docs
4. **Formatting**: Apply project standards
5. **Git**: Meaningful commits
</quality_assurance>

<execution_verification>
<!-- Apply verification loops after implementation -->
<post_build_verification>
  <automated_checks>
  Running verification suite:
  ```bash
  # 1. Test execution
  pnpm test        # Capture all failures
  
  # 2. Type checking
  pnpm typecheck   # Ensure type safety
  
  # 3. Linting
  pnpm lint        # Code quality check
  
  # 4. Build verification
  pnpm build       # Ensure it compiles
  ```
  </automated_checks>
  
  <edge_case_analysis>
  Think: What edge cases might I have missed?
  - Empty state handling: {{checked|missing}}
  - Error boundaries: {{implemented|needed}}
  - Loading states: {{handled|incomplete}}
  - Network failures: {{considered|ignored}}
  - Data validation: {{comprehensive|basic}}
  </edge_case_analysis>
  
  <requirements_verification>
  Does output match requirements?
  - Core functionality: {{complete|partial}}
  - Performance targets: {{met|not_tested}}
  - Accessibility: {{checked|skipped}}
  - Security considerations: {{addressed|pending}}
  </requirements_verification>
  
  <assumption_documentation>
  Documenting build assumptions:
  - Environment: {{assumptions_about_env}}
  - Dependencies: {{version_assumptions}}
  - User behavior: {{usage_assumptions}}
  - Scale: {{performance_assumptions}}
  </assumption_documentation>
</post_build_verification>

<continuous_improvement>
  <if_tests_fail>
  When tests fail:
  1. Analyze failure patterns
  2. Fix root causes (not symptoms)
  3. Add regression tests
  4. Update documentation
  5. Re-run verification
  </if_tests_fail>
  
  <learning_extraction>
  What did we learn?
  - Unexpected complexity: {{what_was_harder}}
  - Missing requirements: {{what_wasnt_specified}}
  - Technical insights: {{new_knowledge}}
  - Process improvements: {{better_approach}}
  </learning_extraction>
</continuous_improvement>
</execution_verification>

<output_format>
## üî® Build Execution: [What Was Built]

### üì• Input Processing
**Received**: [Type of input - URL/code/requirements]
**Interpreted**: [What you understood]
**Context**: [Previous commands or state]

### üéØ Build Target
**Objective**: [What you built]
**Approach**: [How you built it]
**Decisions**: [Key choices made]

### ‚ö° Execution Summary
```bash
# What was executed (parallel tasks shown)
[Task 1] ‚úì Created authentication system
[Task 2] ‚úì Set up database models  
[Task 3] ‚úì Implemented API endpoints
[Task 4] ‚úì Built UI components
```

### üìÅ Created/Modified Files
```
‚úÖ src/auth/index.ts
‚úÖ src/models/user.ts
‚úÖ src/api/auth.ts
‚úÖ src/components/Login.tsx
‚úÖ tests/auth.test.ts
```

### üß™ Verification Results
```
# Automated Checks
‚úì Tests: 12 passing, 0 failing
‚úì Type check: No errors
‚úì Lint: 0 errors, 2 warnings
‚úì Build: Successful (2.3s)

# Edge Cases Verified
‚úì Empty state handling
‚úì Error boundaries in place
‚ö†Ô∏è Network failure handling needs improvement
‚úì Input validation comprehensive

# Requirements Match
‚úì All core features implemented
‚úì Performance targets met (< 3s build)
‚ö†Ô∏è Accessibility: Partial (needs ARIA labels)
‚úì Security: Input sanitization implemented
```

### üöÄ Ready to Use
```bash
# Run the development server
npm run dev

# Or run tests
npm test
```

### üí° What's Next?
Based on what was built, consider:
1. `/user:build add user profile` - Natural next feature
2. `/user:build integrate payment` - Monetization ready
3. `/user:design` - Enhance the UI
4. `/user:brand` - Prepare for launch

### üîó Related Resources
- [Link to relevant docs]
- [Integration guide if applicable]
- [Best practices reference]

### ‚ö†Ô∏è Caveats & Limitations
- **Assumptions made**: 
  - Development environment is properly configured
  - All required dependencies and tools are installed
  - User has necessary permissions for file operations
  - Build follows patterns from previous commands or existing codebase
- **Not addressed**: 
  - Production deployment configurations
  - CI/CD pipeline setup
  - Database migrations and data management
  - Environment-specific configurations
- **Technical debt**: 
  - May skip comprehensive error handling for speed
  - Test coverage might be minimal
  - Documentation updates may lag implementation
- **Alternative approaches**: 
  - Using scaffolding tools or generators
  - Copy-pasting from proven templates
  - Incremental manual building with version control
  - Hiring specialized developers

### üîç Reality Check
- **Environment**: Assumes local dev environment matches production
- **Dependencies**: Version conflicts may arise in real projects
- **Testing**: Basic tests != production-ready test suite
- **Scale**: Local performance != production performance

---
*Built successfully. What should we build next?*

<context_output>
## üîó Command Context
**Command**: /user:build
**Timestamp**: [Current ISO timestamp]
**Session**: `.claude/session/current/`

**Key Findings**:
- Features implemented
- Files created/modified
- Test results
- Build status
- Next logical steps

**For Next Commands**:
```json
{
  "command": "build",
  "features_built": "[list-of-features]",
  "files_modified": "[count-and-paths]",
  "test_status": "[passing/failing]",
  "build_status": "[success/warnings]",
  "phase": "implementation_active",
  "suggested_next": [
    "/user:build [next-feature] - Continue building",
    "/user:docs - Document what was built",
    "/user:design - Enhance UI/UX",
    "/user:brand - Prepare for production"
  ]
}
```
</context_output>
</output_format>

<interoperability_features>
This command seamlessly integrates with:

**From /create:**
- Executes the generated implementation plan
- Follows the architecture decisions
- Uses specified tech stack

**From /vision:**
- Implements the AI-native features
- Builds generative UI concepts
- Follows minimalist philosophy

**From /design:**
- Implements the design system
- Builds component library
- Follows technical specifications

**From /brand:**
- Implements production features
- Adds monitoring and analytics
- Applies security hardening

**With /prime:**
- Uses session context
- Continues from current state
- Maintains awareness

**To /docs:**
- Documents what was built
- Updates architecture docs
- Maintains alignment
</interoperability_features>

<advanced_features>

### URL Intelligence
```markdown
# Automatically handles:
- GitHub repos ‚Üí Clone and analyze
- Documentation ‚Üí Extract patterns
- Stack Overflow ‚Üí Understand solution
- Blog posts ‚Üí Apply techniques
- API docs ‚Üí Implement integration
```

### Smart Inference
```markdown
# Understands context like:
"Here's how Stripe does it [URL]" ‚Üí Implement payment flow
"This error keeps happening [paste]" ‚Üí Fix and prevent
"Make it like this [screenshot]" ‚Üí Build matching UI
"Add Supabase [docs URL]" ‚Üí Full integration
```

### Continuous Flow
```markdown
# Keeps building until done:
Build ‚Üí Test ‚Üí Fix ‚Üí Build more ‚Üí Test ‚Üí Ship
```
</advanced_features>

$ARGUMENTS